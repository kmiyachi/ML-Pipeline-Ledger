{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/Users/kenmiyachi/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n  from numpy.core.umath_tests import inner1d\nINFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pandas_datareader import data as pdr\n",
    "import pandas as pd\n",
    "import fix_yahoo_finance as yf\n",
    "import importlib\n",
    "sys.path.append(\"../MachineLearningStocks/\")\n",
    "from download_historical_prices import *\n",
    "from parsing_keystats import *\n",
    "from backtesting import *\n",
    "from stock_prediction import *\n",
    "sys.path.append(\"../awsQLDB/\")\n",
    "os.environ[\"AWS_PROFILE\"] = \"Insight\"\n",
    "from create_ledger import *\n",
    "from connect_to_ledger import *\n",
    "from create_table import *\n",
    "from create_index import * \n",
    "from insert_document import *\n",
    "from hashlib import sha256\n",
    "import pickle\n",
    "sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[*********************100%***********************]  1 of 1 downloaded\n"
    }
   ],
   "source": [
    "sp500 = build_sp500_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp500_df, stock_df = preprocess_price_data()\n",
    "parsed_df = parse_keystats(sp500_df, stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backtest()\n",
    "# check_yahoo()\n",
    "# current_df = forward()\n",
    "# current_df.to_csv(\"forward_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_stocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectionData(inputData, outHash):\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    commit_hash = repo.head.object.hexsha\n",
    "    collection_data = [\n",
    "        {\n",
    "            'GitHash': commit_hash,\n",
    "            'ScrapeTime': datetime.now(),\n",
    "            'InputData': inputData,\n",
    "            'outputHash': outHash\n",
    "        }\n",
    "    ]\n",
    "    return collection_data\n",
    "\n",
    "def trainingData(inputHash, model):\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    commit_hash = repo.head.object.hexsha\n",
    "    training_data = [\n",
    "        {\n",
    "            'GitHash': commit_hash,\n",
    "            'TrainTime': datetime.now(),\n",
    "            'InputHash': inputHash,\n",
    "            'Model': model\n",
    "        }\n",
    "    ]\n",
    "    return training_data\n",
    "\n",
    "def predictionData(inputHash, model, outHash):\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    commit_hash = repo.head.object.hexsha\n",
    "    prediction_data = [\n",
    "        {\n",
    "            'GitHash': commit_hash,\n",
    "            'InputHash': inputHash,\n",
    "            'Model': model, \n",
    "            'PredictionTime': datetime.now(),\n",
    "            'OutputHash': outHash\n",
    "        }\n",
    "    ]\n",
    "    return prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def mess_up(x):\n",
    "    return x*random.random()\n",
    "    \n",
    "\n",
    "def data_collection(source=\"Yahoo Finance\"):\n",
    "    sp500 = build_sp500_dataset()\n",
    "    sp500['Open'] = sp500['Open'].apply(lambda x: mess_up(x))\n",
    "    sp500['Close'] = sp500['Close'].apply(lambda x: mess_up(x))\n",
    "    sp500.to_csv(\"sp500_index.csv\")\n",
    "    s = pickle.dumps(sp500)\n",
    "    outputHash = sha256(s).hexdigest()\n",
    "    print(outputHash)\n",
    "    # sp500_df, stock_df = preprocess_price_data()\n",
    "    # parse_keystats(sp500_df, stock_df)\n",
    "    data = collectionData(source, outputHash)\n",
    "    dynamic_insert(\"StockMarketPrediction\", \"Collection\", data)\n",
    "\n",
    "\n",
    "def training(modelName=\"RandomForest-2020\"): \n",
    "    model = backtest()\n",
    "    s = pickle.dumps(model)\n",
    "    modelHash = sha256(s).hexdigest()\n",
    "    data = trainingData(modelHash, modelName)\n",
    "    dynamic_insert(\"StockMarketPrediction\", \"Training\", data)\n",
    "\n",
    "def predict(modelName=\"RandomForest-2020\"):\n",
    "    stats = pd.read_csv('./new_keystats.csv')\n",
    "    s = pickle.dumps(stats)\n",
    "    inputHash = sha256(s).hexdigest()\n",
    "    prediction = predict_stocks()\n",
    "    outputHash = sha256(str.encode(prediction)).hexdigest()\n",
    "    data = predictionData(inputHash, modelName, outputHash)\n",
    "    dynamic_insert(\"StockMarketPrediction\", \"Prediction\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[*********************100%***********************]  1 of 1 downloaded\nee8c92f9c2f4a30b5de6349c4556752ae7dc0dc44911a094bbf5e47892b50868\nINFO:insert_document:Inserting some documents in the Collection table...\nINFO:insert_document:Documents inserted successfully!\nClassifier performance\n ====================\nAccuracy score:  0.79\nPrecision score:  0.78\n\n Stock prediction performance report \n ========================================\nTotal Trades: 197\nAverage return for stock predictions:  37.5 %\nAverage market return in the same period:  8.6% \nCompared to the index, our strategy earns  28.9 percentage points more\nINFO:insert_document:Inserting some documents in the Training table...\nINFO:insert_document:Documents inserted successfully!\n13 stocks predicted to outperform the S&P500 by more than 10%:\nTMO WGO DISCA FSLR LRCX BLK WY CMI XRX NTAP GTN LMT APD\nINFO:insert_document:Inserting some documents in the Prediction table...\nINFO:insert_document:Documents inserted successfully!\n"
    }
   ],
   "source": [
    "data_collection()\n",
    "training(\"New Model RF\")\n",
    "predict(\"New Model RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = pd.read_csv('./new_keystats.csv')\n",
    "ks['Price'] = ks['Price'].apply(lambda x: mess_up(x))\n",
    "ks['SP500'] = ks['SP500'].apply(lambda x: mess_up(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}